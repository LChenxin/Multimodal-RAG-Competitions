{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "622a1761",
   "metadata": {},
   "source": [
    "# MinerU → RAG (Windowized) Pipeline with Rerank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b62d0941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\liuch\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\~-mpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\liuch\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\~-mpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 2.14.4 requires dill<0.3.8,>=0.3.0, but you have dill 0.4.0 which is incompatible.\n",
      "llama-index-readers-file 0.4.11 requires pandas<2.3.0, but you have pandas 2.3.1 which is incompatible.\n",
      "tensorflow-intel 2.14.0 requires wrapt<1.15,>=1.11.0, but you have wrapt 1.17.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install mineru[core]>=2.1.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39ff0f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\liuch\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.3.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\liuch\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\liuch\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\liuch\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\liuch\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\liuch\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U --no-cache-dir numpy pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79bd56f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCAL_BASE_URL = ***\n",
      "LOCAL_TEXT_MODEL = ***\n",
      "LOCAL_EMBEDDING_MODEL = ***\n",
      "LOCAL_API_KEY = ***\n",
      "DATAS_DIR          : d:\\Datawhale\\Multimodal-RAG-Competitions\\data\\PDFs\n",
      "MINERU_CONTENT_DIR : d:\\Datawhale\\Multimodal-RAG-Competitions\\notebook\\data_base_json_content\n",
      "MINERU_PAGE_DIR    : d:\\Datawhale\\Multimodal-RAG-Competitions\\notebook\\data_base_json_page_content\n",
      "CHUNKS_JSON        : d:\\Datawhale\\Multimodal-RAG-Competitions\\notebook\\all_pdf_page_chunks.json\n"
     ]
    }
   ],
   "source": [
    "# 1) Setup & config\n",
    "import os, json, re, hashlib, time, glob\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "# repo layout (adjust as needed)\n",
    "BASE = Path.cwd()\n",
    "DATAS_DIR = BASE.parent / \"data\" / \"PDFs\"                       \n",
    "MINERU_CONTENT_DIR = BASE / \"data_base_json_content\"\n",
    "MINERU_PAGE_DIR    = BASE / \"data_base_json_page_content\"\n",
    "CHUNKS_JSON        = BASE / \"all_pdf_page_chunks.json\"\n",
    "\n",
    "\n",
    "MAX_PDFS_TO_PARSE    = 2        # for quick tests; set None for all\n",
    "FORCE_REPARSE        = False    # True to force re-run MinerU even if outputs exist\n",
    "ENABLE_IMAGE_CAPTION = False    # keep False for speed/cost; you can enable later\n",
    "\n",
    "# env (LLM / embeddings / rerank)\n",
    "# Expect these set in your .env or environment\n",
    "for k in [\"LOCAL_BASE_URL\",\"LOCAL_TEXT_MODEL\",\"LOCAL_EMBEDDING_MODEL\",\"LOCAL_API_KEY\"]:\n",
    "    print(k, \"=\", \"***\" if os.getenv(k) else None)\n",
    "    \n",
    "\n",
    "print(\"DATAS_DIR          :\", DATAS_DIR)\n",
    "print(\"MINERU_CONTENT_DIR :\", MINERU_CONTENT_DIR)\n",
    "print(\"MINERU_PAGE_DIR    :\", MINERU_PAGE_DIR)\n",
    "print(\"CHUNKS_JSON        :\", CHUNKS_JSON)\n",
    "\n",
    "# page numbering expected by the evaluation (1 or 0)\n",
    "PAGE_BASE = 1  # set to 1 if the competition uses 1-based pages\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b63e26",
   "metadata": {},
   "source": [
    "## 2) Import the MinerU parse entry\n",
    "We’ll try to import `parse_doc` from either `do_parse.py` or `mineru_parse_pdf.py` (whichever you have).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56bcd7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import asyncio\n",
    "import sys\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "from image_utils.async_image_analysis import AsyncImageAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86ff59bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_all_pdfs(datas_dir, output_base_dir,MAX_PDFS_TO_PARSE):\n",
    "    \"\"\"\n",
    "    步骤1：解析所有PDF，输出内容到 data_base_json_content/\n",
    "    \"\"\"\n",
    "    from mineru_parse_pdf import do_parse\n",
    "    datas_dir = Path(datas_dir)\n",
    "    output_base_dir = Path(output_base_dir)\n",
    "    pdf_files = list(datas_dir.rglob('*.pdf'))\n",
    "    if MAX_PDFS_TO_PARSE:\n",
    "        pdf_files = pdf_files[:MAX_PDFS_TO_PARSE]\n",
    "    if not pdf_files:\n",
    "        print(f\"未找到PDF文件于: {datas_dir}\")\n",
    "        return\n",
    "    for pdf_path in pdf_files:\n",
    "        file_name = pdf_path.stem\n",
    "        with open(pdf_path, \"rb\") as f:\n",
    "            pdf_bytes = f.read()\n",
    "        output_dir = output_base_dir / file_name\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        do_parse(\n",
    "            output_dir=str(output_dir),\n",
    "            pdf_file_names=[file_name],\n",
    "            pdf_bytes_list=[pdf_bytes],\n",
    "            p_lang_list=[\"ch\"],\n",
    "            backend=\"pipeline\",\n",
    "            f_draw_layout_bbox=False,\n",
    "            f_draw_span_bbox=False,\n",
    "            f_dump_md=False,\n",
    "            f_dump_middle_json=False,\n",
    "            f_dump_model_output=False,\n",
    "            f_dump_orig_pdf=False,\n",
    "            f_dump_content_list=True\n",
    "        )\n",
    "        print(f\"已输出: {output_dir / 'auto' / (file_name + '_content_list.json')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01f6bb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_page(content_list):\n",
    "    pages = defaultdict(list)\n",
    "    for item in content_list:\n",
    "        page_idx = item.get('page_idx', 0)\n",
    "        pages[page_idx].append(item)\n",
    "    return dict(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ffa0f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_to_markdown(item, enable_image_caption=True):\n",
    "    \"\"\"\n",
    "    enable_image_caption: 是否启用多模态视觉分析（图片caption补全），默认True。\n",
    "    \"\"\"\n",
    "    # 默认API参数：硅基流动Qwen/Qwen2.5-VL-32B-Instruct\n",
    "    vision_provider = \"guiji\"\n",
    "    vision_model = \"Pro/Qwen/Qwen2.5-VL-7B-Instruct\"\n",
    "    vision_api_key = os.getenv(\"LOCAL_API_KEY\")\n",
    "    vision_base_url = os.getenv(\"LOCAL_BASE_URL\")\n",
    "    \n",
    "    if item['type'] == 'text':\n",
    "        level = item.get('text_level', 0)\n",
    "        text = item.get('text', '')\n",
    "        if level == 1:\n",
    "            return f\"# {text}\\n\\n\"\n",
    "        elif level == 2:\n",
    "            return f\"## {text}\\n\\n\"\n",
    "        else:\n",
    "            return f\"{text}\\n\\n\"\n",
    "    elif item['type'] == 'image':\n",
    "        captions = item.get('image_caption', [])\n",
    "        caption = captions[0] if captions else ''\n",
    "        img_path = item.get('img_path', '')\n",
    "        # 如果没有caption，且允许视觉分析，调用多模态API补全\n",
    "        if enable_image_caption and not caption and img_path and os.path.exists(img_path):\n",
    "            try:\n",
    "                loop = asyncio.new_event_loop()\n",
    "                asyncio.set_event_loop(loop)\n",
    "                async def get_caption():\n",
    "                    async with AsyncImageAnalysis(\n",
    "                        provider=vision_provider,\n",
    "                        api_key=vision_api_key,\n",
    "                        base_url=vision_base_url,\n",
    "                        vision_model=vision_model\n",
    "                    ) as analyzer:\n",
    "                        result = await analyzer.analyze_image(local_image_path=img_path)\n",
    "                        return result.get('title') or result.get('description') or ''\n",
    "                caption = loop.run_until_complete(get_caption())\n",
    "                loop.close()\n",
    "                if caption:\n",
    "                    item['image_caption'] = [caption]\n",
    "            except Exception as e:\n",
    "                print(f\"图片解释失败: {img_path}, {e}\")\n",
    "        md = f\"![{caption}]({img_path})\\n\"\n",
    "        return md + \"\\n\"\n",
    "    elif item['type'] == 'table':\n",
    "        captions = item.get('table_caption', [])\n",
    "        caption = captions[0] if captions else ''\n",
    "        table_html = item.get('table_body', '')\n",
    "        img_path = item.get('img_path', '')\n",
    "        md = ''\n",
    "        if caption:\n",
    "            md += f\"**{caption}**\\n\"\n",
    "        if img_path:\n",
    "            md += f\"![{caption}]({img_path})\\n\"\n",
    "        md += f\"{table_html}\\n\\n\"\n",
    "        return md\n",
    "    else:\n",
    "        return '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5404d792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_pages_to_markdown(pages):\n",
    "    page_md = {}\n",
    "    for page_idx in sorted(pages.keys()):\n",
    "        md = ''\n",
    "        for item in pages[page_idx]:\n",
    "            md += item_to_markdown(item, enable_image_caption=True)\n",
    "        page_md[page_idx] = md\n",
    "    return page_md\n",
    "    return page_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19f624a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_pdfs_to_page_json(input_base_dir, output_base_dir):\n",
    "    \"\"\"\n",
    "    步骤2：将 content_list.json 转为 page_content.json\n",
    "    \"\"\"\n",
    "    input_base_dir = Path(input_base_dir)\n",
    "    output_base_dir = Path(output_base_dir)\n",
    "    pdf_dirs = [d for d in input_base_dir.iterdir() if d.is_dir()]\n",
    "    for pdf_dir in pdf_dirs:\n",
    "        file_name = pdf_dir.name\n",
    "        json_path = pdf_dir / 'auto' / f'{file_name}_content_list.json'\n",
    "        if not json_path.exists():\n",
    "            sub_dir = pdf_dir / file_name\n",
    "            json_path2 = sub_dir / 'auto' / f'{file_name}_content_list.json'\n",
    "            if json_path2.exists():\n",
    "                json_path = json_path2\n",
    "            else:\n",
    "                print(f\"未找到: {json_path} 也未找到: {json_path2}\")\n",
    "                continue\n",
    "        with open(json_path, 'r', encoding='utf-8') as f:\n",
    "            content_list = json.load(f)\n",
    "        pages = group_by_page(content_list)\n",
    "        page_md = assemble_pages_to_markdown(pages)\n",
    "        output_dir = output_base_dir / file_name\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        output_json_path = output_dir / f'{file_name}_page_content.json'\n",
    "        with open(output_json_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(page_md, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"已输出: {output_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de6b6059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_page_content_to_chunks(input_base_dir, output_json_path):\n",
    "    \"\"\"\n",
    "    步骤3：将 page_content.json 合并为 all_pdf_page_chunks.json\n",
    "    \"\"\"\n",
    "    input_base_dir = Path(input_base_dir)\n",
    "    all_chunks = []\n",
    "    for pdf_dir in input_base_dir.iterdir():\n",
    "        if not pdf_dir.is_dir():\n",
    "            continue\n",
    "        file_name = pdf_dir.name\n",
    "        page_content_path = pdf_dir / f\"{file_name}_page_content.json\"\n",
    "        if not page_content_path.exists():\n",
    "            sub_dir = pdf_dir / file_name\n",
    "            page_content_path2 = sub_dir / f\"{file_name}_page_content.json\"\n",
    "            if page_content_path2.exists():\n",
    "                page_content_path = page_content_path2\n",
    "            else:\n",
    "                print(f\"未找到: {page_content_path} 也未找到: {page_content_path2}\")\n",
    "                continue\n",
    "        with open(page_content_path, 'r', encoding='utf-8') as f:\n",
    "            page_dict = json.load(f)\n",
    "        for page_idx, content in page_dict.items():\n",
    "            chunk = {\n",
    "                \"id\": f\"{file_name}_page_{page_idx}\",\n",
    "                \"content\": content,\n",
    "                \"metadata\": {\n",
    "                    \"page\": page_idx,\n",
    "                    \"file_name\": file_name + \".pdf\"\n",
    "                }\n",
    "            }\n",
    "            all_chunks.append(chunk)\n",
    "    with open(output_json_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(all_chunks, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"已输出: {output_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be90dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Setup & config\n",
    "import os, json, re, hashlib, time, glob\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "# repo layout (adjust as needed)\n",
    "BASE = Path.cwd()\n",
    "DATAS_DIR = BASE.parent / \"data\" / \"PDFs\"                       \n",
    "MINERU_CONTENT_DIR = BASE / \"data_base_json_content\"\n",
    "MINERU_PAGE_DIR    = BASE / \"data_base_json_page_content\"\n",
    "CHUNKS_JSON        = BASE / \"all_pdf_page_chunks.json\"\n",
    "\n",
    "\n",
    "MAX_PDFS_TO_PARSE    = 2        # for quick tests; set None for all\n",
    "FORCE_REPARSE        = False    # True to force re-run MinerU even if outputs exist\n",
    "ENABLE_IMAGE_CAPTION = False    # keep False for speed/cost; you can enable later\n",
    "\n",
    "# env (LLM / embeddings / rerank)\n",
    "# Expect these set in your .env or environment\n",
    "for k in [\"LOCAL_BASE_URL\",\"LOCAL_TEXT_MODEL\",\"LOCAL_EMBEDDING_MODEL\",\"LOCAL_API_KEY\"]:\n",
    "    print(k, \"=\", \"***\" if os.getenv(k) else None)\n",
    "    \n",
    "\n",
    "print(\"DATAS_DIR          :\", DATAS_DIR)\n",
    "print(\"MINERU_CONTENT_DIR :\", MINERU_CONTENT_DIR)\n",
    "print(\"MINERU_PAGE_DIR    :\", MINERU_PAGE_DIR)\n",
    "print(\"CHUNKS_JSON        :\", CHUNKS_JSON)\n",
    "\n",
    "# page numbering expected by the evaluation (1 or 0)\n",
    "PAGE_BASE = 1  # set to 1 if the competition uses 1-based pages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "618f3820",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfs = sorted(DATAS_DIR.rglob(\"*.pdf\"))\n",
    "assert pdfs, f\"No PDFs found under {DATAS_DIR}. Put some test PDFs there.\"\n",
    "\n",
    "if MAX_PDFS_TO_PARSE:\n",
    "    pdfs = pdfs[:MAX_PDFS_TO_PARSE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9fea4f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing onnxruntime_pybind11_state: A dynamic link library (DLL) initialization routine failed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mparse_all_pdfs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATAS_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMINERU_CONTENT_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[21], line 5\u001b[0m, in \u001b[0;36mparse_all_pdfs\u001b[1;34m(datas_dir, output_base_dir, MAX_PDFS_TO_PARSE)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_all_pdfs\u001b[39m(datas_dir, output_base_dir,MAX_PDFS_TO_PARSE):\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m    步骤1：解析所有PDF，输出内容到 data_base_json_content/\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmineru_parse_pdf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m do_parse\n\u001b[0;32m      6\u001b[0m     datas_dir \u001b[38;5;241m=\u001b[39m Path(datas_dir)\n\u001b[0;32m      7\u001b[0m     output_base_dir \u001b[38;5;241m=\u001b[39m Path(output_base_dir)\n",
      "File \u001b[1;32md:\\Datawhale\\Multimodal-RAG-Competitions\\mineru_parse_pdf.py:14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmineru\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menum_class\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MakeMode\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmineru\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvlm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvlm_analyze\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m doc_analyze \u001b[38;5;28;01mas\u001b[39;00m vlm_doc_analyze\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmineru\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline_analyze\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m doc_analyze \u001b[38;5;28;01mas\u001b[39;00m pipeline_doc_analyze\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmineru\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline_middle_json_mkcontent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m union_make \u001b[38;5;28;01mas\u001b[39;00m pipeline_union_make\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmineru\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_json_to_middle_json\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m result_to_middle_json \u001b[38;5;28;01mas\u001b[39;00m pipeline_result_to_middle_json\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\mineru\\backend\\pipeline\\pipeline_analyze.py:7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mImage\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mloguru\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logger\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_init\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MineruPipelineModel\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmineru\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_reader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_device\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpdf_classify\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classify\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\mineru\\backend\\pipeline\\model_init.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmfr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munimernet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mUnimernet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UnimernetModel\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mocr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpaddleocr2pytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch_paddle\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PytorchPaddleOCR\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtable\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrapid_table\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RapidTableModel\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menum_class\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelPath\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels_download_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m auto_download_and_get_model_root_path\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\mineru\\model\\table\\rapid_table.py:6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mloguru\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logger\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrapid_table\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RapidTable, RapidTableInput\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmineru\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menum_class\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelPath\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmineru\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels_download_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m auto_download_and_get_model_root_path\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\rapid_table\\__init__.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -*- encoding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# @Author: SWHL\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# @Contact: liekkaskono@163.com\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RapidTable, RapidTableInput\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VisTable\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\rapid_table\\main.py:19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrapid_table\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DownloadModel, LoadImage, Logger, VisTable\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtable_matcher\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TableMatch\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtable_structure\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TableStructurer, TableStructureUnitable\n\u001b[0;32m     21\u001b[0m logger \u001b[38;5;241m=\u001b[39m Logger(logger_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\u001b[38;5;241m.\u001b[39mget_log()\n\u001b[0;32m     22\u001b[0m root_dir \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;18m__file__\u001b[39m)\u001b[38;5;241m.\u001b[39mresolve()\u001b[38;5;241m.\u001b[39mparent\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\rapid_table\\table_structure\\__init__.py:14\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# copyright (c) 2020 PaddlePaddle Authors. All Rights Reserve.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtable_structure\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TableStructurer\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtable_structure_unitable\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TableStructureUnitable\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\rapid_table\\table_structure\\table_structure.py:19\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Dict\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OrtInferSession, TableLabelDecode, TablePreprocess\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTableStructurer\u001b[39;00m:\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config: Dict[\u001b[38;5;28mstr\u001b[39m, Any]):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\rapid_table\\table_structure\\utils.py:26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnxruntime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     27\u001b[0m     GraphOptimizationLevel,\n\u001b[0;32m     28\u001b[0m     InferenceSession,\n\u001b[0;32m     29\u001b[0m     SessionOptions,\n\u001b[0;32m     30\u001b[0m     get_available_providers,\n\u001b[0;32m     31\u001b[0m     get_device,\n\u001b[0;32m     32\u001b[0m )\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrapid_table\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Logger\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mEP\u001b[39;00m(Enum):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\onnxruntime\\__init__.py:61\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnxruntime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m onnxruntime_validation\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m import_capi_exception:\n\u001b[1;32m---> 61\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m import_capi_exception\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnxruntime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnxruntime_inference_collection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     64\u001b[0m     AdapterFormat,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     InferenceSession,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     69\u001b[0m     SparseTensor,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     70\u001b[0m )\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# TODO: thiagofc: Temporary experimental namespace for new PyTorch front-end\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\onnxruntime\\__init__.py:24\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# we need to do device version validation (for example to check Cuda version for an onnxruntime-training package).\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# in order to know whether the onnxruntime package is for training it needs\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# to do import onnxruntime.training.ortmodule first.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# meaningful messages to the user.\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# the saved exception is raised after device version validation.\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnxruntime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pybind_state\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     25\u001b[0m         ExecutionMode,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     26\u001b[0m         ExecutionOrder,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     27\u001b[0m         GraphOptimizationLevel,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     28\u001b[0m         LoraAdapter,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     29\u001b[0m         ModelMetadata,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     30\u001b[0m         NodeArg,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     31\u001b[0m         OrtAllocatorType,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     32\u001b[0m         OrtArenaCfg,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     33\u001b[0m         OrtMemoryInfo,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     34\u001b[0m         OrtMemType,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     35\u001b[0m         OrtSparseFormat,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     36\u001b[0m         RunOptions,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     37\u001b[0m         SessionIOBinding,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     38\u001b[0m         SessionOptions,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     39\u001b[0m         create_and_register_allocator,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     40\u001b[0m         create_and_register_allocator_v2,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     41\u001b[0m         disable_telemetry_events,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     42\u001b[0m         enable_telemetry_events,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     43\u001b[0m         get_all_providers,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     44\u001b[0m         get_available_providers,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     45\u001b[0m         get_build_info,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     46\u001b[0m         get_device,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     47\u001b[0m         get_version_string,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     48\u001b[0m         has_collective_ops,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     49\u001b[0m         set_default_logger_severity,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     50\u001b[0m         set_default_logger_verbosity,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     51\u001b[0m         set_seed,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     52\u001b[0m     )\n\u001b[0;32m     54\u001b[0m     import_capi_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\onnxruntime\\capi\\_pybind_state.py:32\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(system_root, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSystem32\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvcruntime140_1.dll\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m     25\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install the 2019 Visual C++ runtime and then try again. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m                           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mve installed the runtime in a non-standard location \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     27\u001b[0m                           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(other than \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mSystemRoot\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mSystem32), \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     28\u001b[0m                           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmake sure it can be found by setting the correct path.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnxruntime_pybind11_state\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing onnxruntime_pybind11_state: A dynamic link library (DLL) initialization routine failed."
     ]
    }
   ],
   "source": [
    "parse_all_pdfs(DATAS_DIR, MINERU_CONTENT_DIR,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec715a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    base_dir = Path(__file__).parent\n",
    "    datas_dir = base_dir / 'datas'\n",
    "    content_dir = base_dir / 'data_base_json_content'\n",
    "    page_dir = base_dir / 'data_base_json_page_content'\n",
    "    chunk_json_path = base_dir / 'all_pdf_page_chunks.json'\n",
    "    # 步骤1：PDF → content_list.json\n",
    "    parse_all_pdfs(datas_dir, content_dir)\n",
    "    # 步骤2：content_list.json → page_content.json\n",
    "    process_all_pdfs_to_page_json(content_dir, page_dir)\n",
    "    # 步骤3：page_content.json → all_pdf_page_chunks.json\n",
    "    process_page_content_to_chunks(page_dir, chunk_json_path)\n",
    "    print(\"全部处理完成！\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
