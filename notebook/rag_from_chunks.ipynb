{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1b152f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import hashlib\n",
    "from typing import List, Dict, Any\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import concurrent.futures\n",
    "import random\n",
    "\n",
    "from get_text_embedding import get_text_embedding\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "add01a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PageChunkLoader:\n",
    "    def __init__(self, json_path: str):\n",
    "        self.json_path = json_path\n",
    "    def load_chunks(self) -> List[Dict[str, Any]]:\n",
    "        with open(self.json_path, 'r', encoding='utf-8') as f:\n",
    "            return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afbb00f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingModel:\n",
    "    def __init__(self, batch_size: int = 64):\n",
    "        self.api_key = os.getenv('LOCAL_API_KEY')\n",
    "        self.base_url = os.getenv('LOCAL_BASE_URL')\n",
    "        self.embedding_model = os.getenv('LOCAL_EMBEDDING_MODEL')\n",
    "        self.batch_size = batch_size\n",
    "        if not self.api_key or not self.base_url:\n",
    "            raise ValueError('请在.env中配置LOCAL_API_KEY和LOCAL_BASE_URL')\n",
    "\n",
    "    def embed_texts(self, texts: List[str]) -> List[List[float]]:\n",
    "        return get_text_embedding(\n",
    "            texts,\n",
    "            api_key=self.api_key,\n",
    "            base_url=self.base_url,\n",
    "            embedding_model=self.embedding_model,\n",
    "            batch_size=self.batch_size\n",
    "        )\n",
    "\n",
    "    def embed_text(self, text: str) -> List[float]:\n",
    "        return self.embed_texts([text])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e741cd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleVectorStore:\n",
    "    def __init__(self):\n",
    "        self.embeddings = []\n",
    "        self.chunks = []\n",
    "    def add_chunks(self, chunks: List[Dict[str, Any]], embeddings: List[List[float]]):\n",
    "        self.chunks.extend(chunks)\n",
    "        self.embeddings.extend(embeddings)\n",
    "    def search(self, query_embedding: List[float], top_k: int = 3) -> List[Dict[str, Any]]:\n",
    "        from numpy import dot\n",
    "        from numpy.linalg import norm\n",
    "        import numpy as np\n",
    "        if not self.embeddings:\n",
    "            return []\n",
    "        emb_matrix = np.array(self.embeddings)\n",
    "        query_emb = np.array(query_embedding)\n",
    "        sims = emb_matrix @ query_emb / (norm(emb_matrix, axis=1) * norm(query_emb) + 1e-8)\n",
    "        idxs = sims.argsort()[::-1][:top_k]\n",
    "        return [self.chunks[i] for i in idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b79cfc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRAG:\n",
    "    def __init__(self, chunk_json_path: str, model_path: str = None, batch_size: int = 32):\n",
    "        self.loader = PageChunkLoader(chunk_json_path)\n",
    "        self.embedding_model = EmbeddingModel(batch_size=batch_size)\n",
    "        self.vector_store = SimpleVectorStore()\n",
    "    def setup(self):\n",
    "        print(\"加载所有页chunk...\")\n",
    "        chunks = self.loader.load_chunks()\n",
    "        print(f\"共加载 {len(chunks)} 个chunk\")\n",
    "        print(\"生成嵌入...\")\n",
    "        embeddings = self.embedding_model.embed_texts([c['content'] for c in chunks])\n",
    "        print(\"存储向量...\")\n",
    "        self.vector_store.add_chunks(chunks, embeddings)\n",
    "        print(\"RAG向量库构建完成！\")\n",
    "    def query(self, question: str, top_k: int = 3) -> Dict[str, Any]:\n",
    "        q_emb = self.embedding_model.embed_text(question)\n",
    "        results = self.vector_store.search(q_emb, top_k)\n",
    "        return {\n",
    "            \"question\": question,\n",
    "            \"chunks\": results\n",
    "        }\n",
    "\n",
    "    def generate_answer(self, question: str, top_k: int = 3) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        检索+大模型生成式回答，返回结构化结果\n",
    "        \"\"\"\n",
    "        qwen_api_key = os.getenv('LOCAL_API_KEY')\n",
    "        qwen_base_url = os.getenv('LOCAL_BASE_URL')\n",
    "        qwen_model = os.getenv('LOCAL_TEXT_MODEL')\n",
    "        if not qwen_api_key or not qwen_base_url or not qwen_model:\n",
    "            raise ValueError('请在.env中配置LOCAL_API_KEY、LOCAL_BASE_URL、LOCAL_TEXT_MODEL')\n",
    "        q_emb = self.embedding_model.embed_text(question)\n",
    "        chunks = self.vector_store.search(q_emb, top_k)\n",
    "        # 拼接检索内容，带上元数据\n",
    "        context = \"\\n\".join([\n",
    "            f\"[文件名]{c['metadata']['file_name']} [页码]{c['metadata']['page']}\\n{c['content']}\" for c in chunks\n",
    "        ])\n",
    "        # 明确要求输出JSON格式 answer/page/filename\n",
    "        prompt = (\n",
    "            f\"你是一名专业的金融分析助手，请根据以下检索到的内容回答用户问题。\\n\"\n",
    "            f\"请严格按照如下JSON格式输出：\\n\"\n",
    "            f'{{\"answer\": \"你的简洁回答\", \"filename\": \"来源文件名\", \"page\": \"来源页码\"}}'\"\\n\"\n",
    "            f\"检索内容：\\n{context}\\n\\n问题：{question}\\n\"\n",
    "            f\"请确保输出内容为合法JSON字符串，不要输出多余内容。\"\n",
    "        )\n",
    "        client = OpenAI(api_key=qwen_api_key, base_url=qwen_base_url)\n",
    "        completion = client.chat.completions.create(\n",
    "            model=qwen_model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"你是一名专业的金融分析助手。\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.2,\n",
    "            max_tokens=1024\n",
    "        )\n",
    "        import json as pyjson\n",
    "        from extract_json_array import extract_json_array\n",
    "        raw = completion.choices[0].message.content.strip()\n",
    "        # 用 extract_json_array 提取 JSON 对象\n",
    "        json_str = extract_json_array(raw, mode='objects')\n",
    "        if json_str:\n",
    "            try:\n",
    "                arr = pyjson.loads(json_str)\n",
    "                # 只取第一个对象\n",
    "                if isinstance(arr, list) and arr:\n",
    "                    j = arr[0]\n",
    "                    answer = j.get('answer', '')\n",
    "                    filename = j.get('filename', '')\n",
    "                    page = j.get('page', '')\n",
    "                else:\n",
    "                    answer = raw\n",
    "                    filename = chunks[0]['metadata']['file_name'] if chunks else ''\n",
    "                    page = chunks[0]['metadata']['page'] if chunks else ''\n",
    "            except Exception:\n",
    "                answer = raw\n",
    "                filename = chunks[0]['metadata']['file_name'] if chunks else ''\n",
    "                page = chunks[0]['metadata']['page'] if chunks else ''\n",
    "        else:\n",
    "            answer = raw\n",
    "            filename = chunks[0]['metadata']['file_name'] if chunks else ''\n",
    "            page = chunks[0]['metadata']['page'] if chunks else ''\n",
    "        # 结构化输出\n",
    "        return {\n",
    "            \"question\": question,\n",
    "            \"answer\": answer,\n",
    "            \"filename\": filename,\n",
    "            \"page\": page,\n",
    "            \"retrieval_chunks\": chunks\n",
    "        }\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
